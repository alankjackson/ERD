---
title: "FEMA_extra"
author: "Alan Jackson"
format: html
editor: source
---

## Put together FEMA flood data not on the coast


```{r setup}

library(tidyverse)
library(gt)
library(tidycensus)

googlecrs <- "EPSG:4326"

pq_path <- "/home/ajackson/Dropbox/Rprojects/ERD/Data/"
path <- "/home/ajackson/Dropbox/Rprojects/ERD/FEMA/"

FEMA <- readRDS(paste0(pq_path, "FEMA_Flood.rds"))

```

##    Functions

```{r}

options(tigris_use_cache = TRUE)

get_ACS <- function(State, Year) {
  # Now let's prepare the block-group data
  
  acs_vars <- c(Pop="B01001_001", # ACS population estimate
                Med_inc="B19013_001", # median household income, blk grp
                Per_cap_inc="B19301_001", # Per capita income, blk grp
                Fam="B17010_001", # Families, blk grp
                Fam_in_poverty="B17010_002", # Families in poverty, blk grp
                Aggreg_inc="B19025_001", # Aggregate household income, blk grp
                Households="B11012_001", # Households, blk grp
                Renters="B25008_003", # Renters pop, blk grp
                RentersH="B25003_003", # Renters houses, blk grp
                Owners="B25008_002", #   Home owners pop blk grp
                OwnersH="B25003_002", #   Home owners houses blk grp
                Mobile="B25024_010", #  Mobile homes blk grp
                Med_age="B01002_001") # median age, blk grp
  ACS <- get_acs(geography="block group",
                 variables=acs_vars,
                 year=Year,
                 state=State,
                 output="wide",
                 geometry=TRUE)
  
  ACS <- ACS %>% 
    mutate(Pct_poverty=as.integer(signif(100*Fam_in_povertyE/FamE, 0))) %>% 
    select(GEOID, Pop_acs=PopE, Med_inc=Med_incE, Per_cap_in=Per_cap_incE,
           Fam=FamE, Fam_in_poverty=Fam_in_povertyE, Aggreg_inc=Aggreg_incE,
           Pct_poverty, Households=HouseholdsE, Renters=RentersE, 
           RentersH=RentersHE, Owners=OwnersE, OwnersH=OwnersHE, 
           Mobile=MobileE, Med_ageE=Med_ageE)
  
  ACS <- sf::st_transform(ACS, googlecrs)  
  
  return(ACS)
}

```

##        Clean up data

```{r}

FEMA2 <- FEMA %>% 
  select(dateOfLoss, state, countyCode, ratedFloodZone, occupancyType,
         amountPaidOnBuildingClaim, yearOfLoss, buildingDamageAmount,
         buildingPropertyValue, buildingReplacementCost, causeOfDamage, 
         floodEvent, waterDepth, floodZoneCurrent, censusTract, 
         censusBlockGroupFips, nfipCommunityName, eventDesignationNumber) %>% 
  arrange(dateOfLoss)  %>% 
  filter(occupancyType %in% c(1,2,3,11,12,13,14,15))


FEMA2 <- FEMA2 %>% 
  filter(!is.na(censusBlockGroupFips)) %>% 
  select(dateOfLoss, ratedFloodZone, occupancyType, amountPaidOnBuildingClaim,
       yearOfLoss,  causeOfDamage, floodEvent, waterDepth, censusBlockGroupFips,
       nfipCommunityName, state, countyCode) %>% 
  mutate(Month=lubridate::month(dateOfLoss, label=TRUE)) %>% 
  mutate(Occupancy=case_when(
            occupancyType==1 | occupancyType==11 | occupancyType==15 ~ "Own",
            occupancyType==14 ~ "Mobile",
            .default="Rent"
  ))      

#   Collapse data by GEOID

FEMA3 <- FEMA2 %>% 
  mutate(week_yr=paste(lubridate::year(dateOfLoss), 
                       lubridate::week(dateOfLoss))) %>% 
  group_by(censusBlockGroupFips, Occupancy) %>% 
    summarise(Num_Claims=n(),
              Num_dates=n_distinct(week_yr),
              # Year=first(yearOfLoss),
              # Month=first(Month),
              State=first(state),
              County=first(countyCode)) %>% 
  ungroup() %>% 
  pivot_wider(names_from = Occupancy, values_from = c(Num_Claims, Num_dates),
              values_fill=0) %>% 
  replace_na(list(Num_Claims_Mobile=0,
                  Num_dates_Mobile=0)) %>%  
  mutate(Num_Claims=Num_Claims_Own+Num_Claims_Rent+Num_Claims_Mobile,
         Num_dates=Num_dates_Own+Num_dates_Rent+Num_dates_Mobile) 

#   Pull out storm names to later add back to file

Storms <- FEMA2 %>% 
  filter(!is.na(censusBlockGroupFips)) %>% 
  mutate(floodEvent=stringr::str_remove(floodEvent, "Hurricane ")) %>% 
  mutate(floodEvent=stringr::str_replace(floodEvent, "Tropical Storm", "T.S.")) %>% 
  replace_na(list(floodEvent="Unk")) %>% 
  mutate(floodEvent=paste(floodEvent, yearOfLoss, Month)) %>% 
  group_by(censusBlockGroupFips) %>% 
    summarize(floodEvent=paste(unique(floodEvent), collapse=", ")) %>% 
  ungroup()  

FEMA3 <-  FEMA3 %>% 
  inner_join(., Storms, by="censusBlockGroupFips")  %>% 
  filter(!State=="UN") %>% 
  filter(Num_Claims>9) # 10 or more claims total

# causeOfDamage:
# 0 : Other causes; 
# 1 : Tidal water overflow; 
# : Stream, river, or lake overflow; 
# 3 : Alluvial fan overflow; 
# 4 : Accumulation of rainfall or snowmelt; 
# 7 : Erosion-demolition; 
# 8 : Erosion-removal; 
# 9 : Earth movement, landslide, land subsidence, sinkholes, etc.


###   occupancy types
# 1=single family residence; 
# 2 = 2 to 4 unit residential building; 
# 3 = residential building with more than 4 units; 
# 4 = Non-residential building; 
# 6 = Non Residential - Business; 
# 11 = Single-family residential building with the exception of a mobile home or a single residential unit within a multi unit building; 
# 12 = A residential non-condo building with 2, 3, or 4 units seeking insurance on all units; 
# 13 = A residential non-condo building with 5 or more units seeking insurance on all units; 
# 14 = Residential mobile/manufactured home; 
# 15 = Residential condo association seeking coverage on a building with one or more units; 
# 16 = Single residential unit within a multi-unit building; 
# 17 = Non-residential mobile/manufactured home; 
# 18 = A non-residential building; 
# 19 = a non-residential unit within a multi-unit building;

```

##    Loop through states and attach census data, then save output by state

```{r}

States <- unique(FEMA3$State)

state="AL"

for (state in States) {
  
  if (state=="VI") {next}
  print(paste("---->", state))
  #   First get block groups for 2020 census  
  Census2020 <- get_ACS(state, 2020)
  Census2015 <- get_ACS(state, 2019)
  # Census2013 <- get_ACS(state, 2013) # 2009-2013
  
  foo <- FEMA3 %>% 
    filter(State==state) %>% 
    left_join(., Census2020, by=join_by("censusBlockGroupFips"=="GEOID")) %>%  
    sf::st_as_sf() 
  
  Remainder <- foo %>% 
    sf::st_drop_geometry() %>% 
    filter(is.na(Pop_acs)) %>% 
    select(-Pop_acs, -Med_inc, -Per_cap_in, -Fam, -Fam_in_poverty, -Aggreg_inc,
           -Pct_poverty, -Households, -Med_ageE)  
  
  #   Now take the ones that didn't match and look for 2010 census
  
  foo2 <- left_join(Remainder, Census2015, 
                    by=join_by("censusBlockGroupFips"=="GEOID")) %>%  
          sf::st_as_sf() 
  
  Remainder <- foo2 %>% 
    filter(is.na(Pop_acs)) %>% 
    select(-Pop_acs, -Med_inc, -Per_cap_in, -Fam, -Fam_in_poverty, -Aggreg_inc,
           -Pct_poverty, -Households, -Med_ageE) %>% 
    sf::st_drop_geometry()
  
  # foo3 <- left_join(Remainder, Census2013, 
  #                   by=join_by("censusBlockGroupFips"=="GEOID"))  
  
  Good_data <- foo %>% 
    filter(!is.na(Pop_acs)) %>% 
    bind_rows(., foo2 %>% filter(!is.na(Pop_acs))) %>% 
    filter(Pop_acs>50) %>% 
    mutate(ClaimsPerHousehold=signif(Num_Claims/Households, 2)) %>% 
    sf::st_as_sf() %>% 
    sf::st_make_valid()
  
  saveRDS(Remainder, paste0(path, "FEMA_extra_remainder_", state, ".rds"))
  saveRDS(Good_data, paste0(path, "FEMA_extra_", state, ".rds"))
  
}


  
```

##    Test histograms

```{r}

foobar <- readRDS(paste0(path, "FEMA_extra_", "AL", ".rds"))

p1 <- foobar %>% 
  filter(Num_Claims>100) %>% 
  ggplot(aes(x=Num_Claims)) +
  geom_histogram() +
  labs(title="Number of Claims per Census Blk-Grp",
       x="Number of Claims",
       y="Blk Grps")

p2 <- foobar %>% 
  filter(ClaimsPerHousehold>0.2) %>% 
  ggplot(aes(x=ClaimsPerHousehold)) +
  geom_histogram() +
  labs(title="Number of Claims per Household",
       x="Number of Claims per Household",
       y="Blk Grps")

gridExtra::grid.arrange(p1, p2, top="Claims>100, Claims/House>0.2")
```

##    Count polygon vertices and test ways to reduce the number

```{r}

#   simplify a polygon to less than 20 vertices
dePop <- function(Single_poly, Max_vertices=20){
  vertices <- nrow(sf::st_coordinates(Single_poly)) 
  New_poly <- Single_poly
  Tolerance <- 50
  while(vertices>Max_vertices) {
    New_poly <- sf::st_simplify(Single_poly, dTolerance = Tolerance)
    vertices <- nrow(sf::st_coordinates(New_poly))
    print(paste("Tolerance, Vertices", Tolerance, vertices))
    Tolerance <- Tolerance + 50
  }
  return(New_poly)
}

foo4 <- dePop(foo2[58,], 15)
foo5 <- as_tibble(sf::st_coordinates(foo4))  
foo5 <- foo5[1:nrow(foo5)-1,] # drop last row (duplicated coordinate)
BegX <- foo5[1,]$X
BegY <- foo5[1,]$Y
EndX <- foo5[nrow(foo5),]$X
EndY <- foo5[nrow(foo5),]$Y
  
foo5 <- foo5 %>% unite("Z", Y:X, sep=",") %>% 
  select(Z)
foo5 <- paste(unlist(as.list(foo5)), collapse="|")
# URL <- paste0("https://www.google.com/maps/@?api=1&map_action=map&center=",
#                   "--lat--", "%2C1", 
#                   "--lng--", "&zoom=", "--zoom--",
# URL <- paste0("https://www.google.com/maps/dir/",
URL <- paste0("https://www.google.com/maps/embed",
                  "&poly=|",
              "?pb=!1m18!1m12!1m3!1d10000!2d-74.0060!3d40.7128!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x0%3A0x0!2sNew%20York!5e0!3m2!1sen!2sus!4v1674598900!5m2!1sen!2sus",
                  # "32.92563,-88.206393/32.932093,-88.175329/?waypoints=",
                  # BegY, ",", BegX, "/", EndY, ",", EndX, "/?waypoints=",
                  # BegY, ",", BegX, "/", EndY, ",", EndX, "/?waypoints=",
                  foo5,"|"
              )
    # "https://www.google.com/maps/search/?api=1&query=markers:path:37.7833,-122.4167|37.7833,-122.4000|37.7900,-122.4000|37.7900,-122.4167"


foo2 <- sf::st_cast(foobar, "POLYGON", do_split = FALSE)
foo3 <- sf::st_simplify(foo2, preserveTopology = TRUE, dTolerance = 50)

unlist(lapply(1:nrow(foo2), \(i) nrow(sf::st_coordinates(foo2[i,])) ))
unlist(lapply(1:nrow(foo3), \(i) nrow(sf::st_coordinates(foo3[i,])) ))

  tmap::tmap_options(basemaps="OpenStreetMap")
  tmap::tmap_mode("view")
foo4 <- sf::st_simplify(foo2[18,], preserveTopology = TRUE, dTolerance = 100)  
foo4 <- dePop(foo2[58,], 15)
# unlist(lapply(1:nrow(foo3[17,]), \(i) nrow(sf::st_coordinates(foo3[17,][i,])) ))
# unlist(lapply(1:nrow(foo4), \(i) nrow(sf::st_coordinates(foo4[i,])) ))
  sf::st_as_sf(foo4) %>%
  tmap::tm_shape() +
  tmap::tm_polygons("Num_Claims", border.col="red", alpha=0) 

```

##    Test out creating a pdf report

```{r}

My_blkgrp <- "190130026045"
state <- "IA"
comment <- "This is my comment about this data"
# "https://www.google.com/maps/@?api=1&map_action=map&center=42.5399908708896%2C-92.4296092987061&zoom=13"

params <- list()

pdf <-  rmarkdown::render(tempReport, 
          output_file = "FEMA_flooding.pdf",
          params = params,
          envir = new.env(parent = globalenv())
        )

```














